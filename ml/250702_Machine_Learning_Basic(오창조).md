## 📅 학습 날짜  

- 2025-07-02 (화)


## 📌 키워드 및 요약 정리
- EDA(Exploratory Data Analysis : 탐색적 데이터 분석) 
  - 데이터를 탐색함으로써 각 변수의 의미와 특성 분포를 이해하는 과정 
  - 데이터의 명확한 이해 > 정확한 문제 정의와 모델링이 가능
  - 데이터셋의 편향
    - 데이터 수집 및 정제과정 개선
  - 생존자 편향
    - 살아돌아온 흔적에 반대는 살아돌아 오지 못한 데이터의 편향
- 선형회귀
  - 독립변수(x)와 종속변수(y) 사이의 관계를 선형적으로 모델링하는 가장 기본적인 머신러닝의 알고리즘
  - 선형회귀의 목적은 직성 방정식을 찾는 것


## 📘 개념 정리  

### 딥러닝 < 머신러닝 < 인공지능 

- 약인공지능
  - Weak AI 정해져 있는 과제들을 잘 수행하는 인공지능

- 강인공지능
  - 사람처럼 복합적인 사고를 토해 어떤일이든 수행하는 인공지능

### 딥러닝이란
- 학습을 한다는 것
  - 정해진 파라메트릭 함수, 모델에서
  - 데이터의 인풋값에 대한 모델 예측값과 라벨의 차이로 계산되는 손실 함수를 최소화하는
  - 파라미터 세타를 찾아내는 것
- 머신러닝으로 만들수 있는 함수들은? 
  - 어떤 것이든 확장할 수 있음. 그러나, 쉽게 된다는 것 (X)

### ML의 확장성과 한계
- 머신러닝을 위한 문제정의
- 데이터의 종류
  - 정량적 정보 : 테이블 형태로 구조화되어있는 데이터셋
    - 엑셀, CSV
  - 정성적 정보 : 변수들이 구조화되어 있지 않은, 정성적 정보로 구성된 데이터셋
    - 텍스트, 이미지, 동영상, 음악, 녹음파일 등
- 데이터의 수치적 표현방법
  - 글자별, 단어별 인덱싱 > 자연어 표현에 사용
  - 비트맵, 컴퓨터 비전 > 이미지, 동영상
  - Raw Wave 표현 방법(스펙트로그램, 음성처리)
  - 추천시스템

### ML 데이터의 품질
- 데이터의 품질
  - 편향성이 없는 것
- 라벨 노이즈
  - 결측치(NaN, NA, null), 이상치, 틀린라벨(모호성), 중복라벨, 도메인 외의 샘플
- Silent Failure
  - 데이터 전처리 단계에 의해서 발생하는 경우가 많음
- EDA(탐색적 데이터 분석)
  - 데이터셋의 기본적인 정보를 파악
  - 이상치와 결측치 파악
    - 박스플롯
  - 샘플을 램덤추출해보며 패턴파악
  - 각 변수의 통계량, 분포 확인
    - 비대칭도, 첨도, 상관계수, 상관행렬 그림
  - 데이터의 전처리
    - 피처 스케일 조정 > 표준화 > 정규화
  - 변수간의 관계 파악 등의 과정을 진행하며, 노이즈나 편향에 대한 분석도 수시로 진행한다.

### 선형회귀 모델 원리와 해법
#### 1. 원리
  - 선형회귀(Linear Regression)는 독립 변수(x)와 종속 변수(y) 사이의 관계를 선형(직선)으로 모델링하는 가장 기본적인 머신러닝 알고리즘
  - 원리 : 선형회귀의 목적은 다음과 같은 직선 방정식을 찾는 것

#### 2. 손실함수(MES)

#### 3. 최적화의 해법
  -  해석적 방법 : 정규방정식(Normal Equation)
      - 정확한 해를 구할 수 있지만,
      - X 가 매우 크면 계산량이 많아짐(역행렬 계산)
  - 수치적 방법 : 경사 하강법(Gradient Descent)
      - MES를 줄이기 위해 반복적으로 가중치를 조정하는 방식
      - 손실 함수의 기울기(gradient)를 따라 가중치 업데이트

#### 4. 단순선형 회귀모델과 상관관계 분석
  - 한 변수가 변할 때 다른 변수가 어떻게 변화하는지, 상관관계 분석
  - 상관관계(Correlation) : 한 변수가 변화할 때 다른 변수가 함께 변화하는 경향성을 보일 때 두 변수의 관계
  - 인과관계(Causation) : 한 변수의 변화가 원인이 되어 그 결과로서 다른 변수를 변화시킬 때 두 변수의 관계
  - 인과관계가 있는 변수는 상관관계도 있지만, 반대의 관계는 성립하지 않음.

#### 상관관계 분석의 가정
  - 선형성 : 두 변인 X와 Y의 관계가 직선적이어야 함
  - 등분산성 : X의 값에 관계없이 Y의 분산이 일정해야 함
  - 정규성 : 각 변인은 모두 정규분포를 따라야 한다.
  - 독립성 : 각 샘플들은 모두 독립적이어야 한다.
  - 대상 변수들이 이 가정을 만족하지 않는다면 상관계수를 구해도 의미가 없음

#### 상관계수 행렬의 시각화
  - 상관행렬 : 입력 피쳐에 포함된 모든 변수 쌍의 조합에 대한 상관계수를 행렬의 형태로 나타낸 것
  - 데이터 탐색 시, 변수간의 상호 연관성을 파악하는데 유용하다.
  - 공선성과 다중공선성 : 상관행렬을 시각화시 몇몇 변수들간의 상관계수가 1.0 또는 -1.0으로나타내는 경우, 두 변수사이에 공선성이 있다고 표현함.

### 분류모델의 정의와 개념
#### 1. 선형모델을 활용한 분류문제 모델링
  - 이진분류문제와 로지스틱 회귀
  - 로지스틱 희귀모델의 학습
    - 시그모이드 함수 > 딥러닝에서는 시그모이드 함수 => 로지스틱 회귀 함수
    - 크로스엔트로피(BCE) => 손실함수
      - 크로스엔트로피를 사용하는 이유 : BCE를 쓰는게 훨씬 학습이 잘됨
      - 로지스틱 함수와 결합시 미분식이 매우 간단해 짐
  - 다중분류문제의 모델링
    - 원 핫 인코딩 : 
    - 소프트맥스 : 
    - 이산형 변수의 다중분류 모델링

#### 2. 다양한 방식의 분류문제 모델링
  - k-최근접 이웃(kNN) 알고리즘 : 특정 인풋이 들어왔을 때, 학습 데이터셋에서 가장 근접한 k개의 라벨을 기준으로 출력값을 결정하는 간단한 방식
  - 결정트리와 랜덤 포레스트 : 독리변수(X)내의 대소 관계나 특정 임계값(threshold)과의 비교등의 판단을 계층적으로 적용하여 최종 결과를 분류하는 모델
  - 서포트벡터머신(SVM)을 활용한 이진분류
    - 결정경계
    - 선형분리가능한 데이터셋
    - 서포트 벡터 머신 : 선형분리 가능한 데이터셋에서, 데이터의 두 클래스를 가장 잘 분리하는 결정경계를 찾아내기 위한 방법론
    - 커널 트릭

### 비지도학습이란
#### 1.비지도학습(Unsupervised Learning) 
- 학습용 라벨(Y_train)를 사용하지 않고 입력 데이터(x)로만 모델을 학습하는 방법론
- 군집화와 분류모델의 차이

##

## ❓ 어려웠던 부분  
_예시:_
- _Autograd 연산 그래프에서 비선형 함수의 그래디언트 계산 방식이 헷갈렸습니다._  
- _Softmax와 CrossEntropyLoss가 왜 함께 쓰이는지 직관적으로 잘 이해되지 않았습니다._



## 💬 질문 또는 토론 유도  
_예시:_
- _파라미터 초기화 방식이 학습 성능에 어떤 영향을 주나요?_
- _CNN의 커널 사이즈를 줄이면 어떤 효과가 생길까요?_



## 🔗 참고 자료 (선택)  
_예시:_
- _[PyTorch 공식 문서 - Autograd](https://pytorch.org/docs/stable/autograd.html)_
- _CS231n 강의 노트 - Backpropagation 섹션_
